{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6359 entries, 0 to 6358\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      6359 non-null   int64 \n",
      " 1   text    6359 non-null   object\n",
      " 2   label   6359 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 149.2+ KB\n",
      "None\n",
      "   id                                               text  label\n",
      "0   0  Renfe afronta mañana un nuevo día de paros par...      2\n",
      "1   1       Presupuesto populista con cimientos frágiles      2\n",
      "2   2  Biden no cree que la OPEP+ vaya a ayudar con l...      2\n",
      "3   3  La deuda de las familias cae en 25.000 millone...      0\n",
      "4   4  Bestinver: no hay \"momento más inoportuno\" par...      2\n",
      "\n",
      "Test Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1621 entries, 0 to 1620\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      1621 non-null   int64 \n",
      " 1   text    1621 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.5+ KB\n",
      "None\n",
      "   id                                               text\n",
      "0   0  Las empresas chinas piden menos burocracia par...\n",
      "1   1  Enrique Escalante (Havas): “Todos tenemos que ...\n",
      "2   2  Banca March confía su gestión empresarial a la...\n",
      "3   3  Garamendi, sobre la ruptura de la fusión: \"Hay...\n",
      "4   4  El Gobierno vasco da por hecho la continuidad ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "train_path = \"FinancES_train_kaggle.csv\"  # Ruta del archivo de entrenamiento\n",
    "test_path = \"FinancES_test_kaggle.csv\"    # Ruta del archivo de prueba\n",
    "\n",
    "# Leer los archivos CSV\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Mostrar información de los datos cargados\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.info())\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.info())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de las clases en el conjunto de entrenamiento:\n",
      "label\n",
      "2    2935\n",
      "0    2818\n",
      "1     606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores nulos en el conjunto de entrenamiento:\n",
      "id       0\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en el conjunto de prueba:\n",
      "id      0\n",
      "text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploracion\n",
    "\n",
    "# Identificar distribución de las clases\n",
    "print(\"\\nDistribución de las clases en el conjunto de entrenamiento:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "print(\"\\nValores nulos en el conjunto de entrenamiento:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nValores nulos en el conjunto de prueba:\")\n",
    "print(test_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de la longitud de los textos en el conjunto de entrenamiento:\n",
      "count    6359.000000\n",
      "mean       72.736751\n",
      "std        20.955372\n",
      "min         3.000000\n",
      "25%        61.000000\n",
      "50%        72.000000\n",
      "75%        84.000000\n",
      "max       211.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de longitud de los textos\n",
    "train_df[\"text_length\"] = train_df[\"text\"].apply(len)\n",
    "\n",
    "print(\"\\nEstadísticas de la longitud de los textos en el conjunto de entrenamiento:\")\n",
    "print(train_df[\"text_length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto preprocesado:\n",
      "0    renfe afronta mañana un nuevo día de paros par...\n",
      "1         presupuesto populista con cimientos frágiles\n",
      "2    biden no cree que la opep+ vaya a ayudar con l...\n",
      "3    la deuda de las familias cae en 25.000 millone...\n",
      "4    bestinver: no hay \"momento más inoportuno\" par...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Normalización: convertir a minúsculas\n",
    "train_df[\"text\"] = train_df[\"text\"].str.lower()\n",
    "test_df[\"text\"] = test_df[\"text\"].str.lower()\n",
    "\n",
    "print(\"\\nTexto preprocesado:\")\n",
    "print(train_df[\"text\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Descargar recursos necesarios\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "train_path = \"FinancES_train_kaggle.csv\"  # Ruta del archivo de entrenamiento\n",
    "test_path = \"FinancES_test_kaggle.csv\"    # Ruta del archivo de prueba\n",
    "\n",
    "# Cargar el modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from collections import Counter\n",
    "\n",
    "# Contar palabras más frecuentes en el dataset\n",
    "all_words = \" \".join(train_df[\"text\"]).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Eliminar palabras que aparecen en más del 80% de los documentos\n",
    "frequent_words = {word for word, freq in word_freq.items() if freq > 0.8 * len(train_df)}\n",
    "\n",
    "# Inicializar el Stemmer para español\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "# Lista de stopwords personalizada\n",
    "custom_stopwords = set(stopwords.words('spanish'))\n",
    "\n",
    "# Agregar palabras irrelevantes para titulares financieros\n",
    "custom_stopwords.update({\"día\", \"años\", \"mes\", \"nuevo\", \"euros\"})\n",
    "\n",
    "# Añadir palabras frecuentes a la lista de stopwords\n",
    "custom_stopwords.update(frequent_words)\n",
    "\n",
    "# Función de preprocesamiento con Stemming y stopwords mejoradas\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Eliminar signos de puntuación y caracteres especiales, manteniendo números\n",
    "    tokens = [re.sub(r\"(?<!\\d)[^\\w\\s](?!\\d)\", \"\", token) for token in tokens]\n",
    "    \n",
    "    # Eliminar stopwords personalizadas\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    \n",
    "    # Aplicar Stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6359 entries, 0 to 6358\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           6359 non-null   int64 \n",
      " 1   text         6359 non-null   object\n",
      " 2   label        6359 non-null   int64 \n",
      " 3   text_length  6359 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 198.8+ KB\n",
      "None\n",
      "   id                                               text  label  text_length\n",
      "0   0        renf afront mañ nuev dia par parcial maquin      2           71\n",
      "1   1                    presupuest popul cimient fragil      2           44\n",
      "2   2                 bid cre opep vay ayud preci petrol      2           69\n",
      "3   3  deud famili caer 25000 millon 2015 marc nivel ...      0           91\n",
      "4   4                    bestinv moment inoportun brexit      2           57\n",
      "\n",
      "Test Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1621 entries, 0 to 1620\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      1621 non-null   int64 \n",
      " 1   text    1621 non-null   object\n",
      " 2   label   1621 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 38.1+ KB\n",
      "None\n",
      "   id                                               text  label\n",
      "0   0         empres chin ped men burocraci invert españ      2\n",
      "1   1  enriqu escal hav trabaj soft skills mund cambi...      0\n",
      "2   2  banc march conf gestion empresarial nub microsoft      0\n",
      "3   3         garamendi ruptur fusion noviazg lueg retom      0\n",
      "4   4            gobiern vasc dar hech continu euskaltel      0\n"
     ]
    }
   ],
   "source": [
    "# Mostrar información de los datos cargados\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.info())\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.info())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675314465408805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69       546\n",
      "           1       0.86      0.24      0.37       127\n",
      "           2       0.70      0.71      0.70       599\n",
      "\n",
      "    accuracy                           0.68      1272\n",
      "   macro avg       0.73      0.56      0.59      1272\n",
      "weighted avg       0.69      0.68      0.66      1272\n",
      "\n",
      "   id                                               text  label\n",
      "0   0         empres chin ped men burocraci invert españ      2\n",
      "1   1  enriqu escal hav trabaj soft skills mund cambi...      0\n",
      "2   2  banc march conf gestion empresarial nub microsoft      0\n",
      "3   3         garamendi ruptur fusion noviazg lueg retom      0\n",
      "4   4            gobiern vasc dar hech continu euskaltel      0\n"
     ]
    }
   ],
   "source": [
    "# Vectorización TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), norm='l2')\n",
    "X = vectorizer.fit_transform(train_df[\"text\"])\n",
    "y = train_df[\"label\"]\n",
    "\n",
    "# Separar conjunto de entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar SMOTE para balancear las clases en el conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entrenar modelo SVM con los datos balanceados\n",
    "svm_model = SVC(kernel='linear', class_weight='balanced', random_state=42, C=10)\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = svm_model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Transformar los datos de test y generar predicciones\n",
    "X_test = vectorizer.transform(test_df[\"text\"])\n",
    "test_predictions = svm_model.predict(X_test)\n",
    "\n",
    "test_df[\"label\"] = test_predictions\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'submission.csv' creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # Crear archivo CSV con el formato requerido\n",
    "    test_df[['id', 'label']].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    print(\"Archivo 'submission.csv' creado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6359 entries, 0 to 6358\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      6359 non-null   int64 \n",
      " 1   text    6359 non-null   object\n",
      " 2   label   6359 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 149.2+ KB\n",
      "None\n",
      "   id                                               text  label\n",
      "0   0  Renfe afronta mañana un nuevo día de paros par...      2\n",
      "1   1       Presupuesto populista con cimientos frágiles      2\n",
      "2   2  Biden no cree que la OPEP+ vaya a ayudar con l...      2\n",
      "3   3  La deuda de las familias cae en 25.000 millone...      0\n",
      "4   4  Bestinver: no hay \"momento más inoportuno\" par...      2\n",
      "\n",
      "Test Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1621 entries, 0 to 1620\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      1621 non-null   int64 \n",
      " 1   text    1621 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.5+ KB\n",
      "None\n",
      "   id                                               text\n",
      "0   0  Las empresas chinas piden menos burocracia par...\n",
      "1   1  Enrique Escalante (Havas): “Todos tenemos que ...\n",
      "2   2  Banca March confía su gestión empresarial a la...\n",
      "3   3  Garamendi, sobre la ruptura de la fusión: \"Hay...\n",
      "4   4  El Gobierno vasco da por hecho la continuidad ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "train_path = \"FinancES_train_kaggle.csv\"  # Ruta del archivo de entrenamiento\n",
    "test_path = \"FinancES_test_kaggle.csv\"    # Ruta del archivo de prueba\n",
    "\n",
    "# Leer los archivos CSV\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Mostrar información de los datos cargados\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.info())\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.info())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de las clases en el conjunto de entrenamiento:\n",
      "label\n",
      "2    2935\n",
      "0    2818\n",
      "1     606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores nulos en el conjunto de entrenamiento:\n",
      "id       0\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos en el conjunto de prueba:\n",
      "id      0\n",
      "text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploracion\n",
    "\n",
    "# Identificar distribución de las clases\n",
    "print(\"\\nDistribución de las clases en el conjunto de entrenamiento:\")\n",
    "print(train_df[\"label\"].value_counts())\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "print(\"\\nValores nulos en el conjunto de entrenamiento:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nValores nulos en el conjunto de prueba:\")\n",
    "print(test_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de la longitud de los textos en el conjunto de entrenamiento:\n",
      "count    6359.000000\n",
      "mean       72.736751\n",
      "std        20.955372\n",
      "min         3.000000\n",
      "25%        61.000000\n",
      "50%        72.000000\n",
      "75%        84.000000\n",
      "max       211.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de longitud de los textos\n",
    "train_df[\"text_length\"] = train_df[\"text\"].apply(len)\n",
    "\n",
    "print(\"\\nEstadísticas de la longitud de los textos en el conjunto de entrenamiento:\")\n",
    "print(train_df[\"text_length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto preprocesado:\n",
      "0    renfe afronta mañana un nuevo día de paros par...\n",
      "1         presupuesto populista con cimientos frágiles\n",
      "2    biden no cree que la opep+ vaya a ayudar con l...\n",
      "3    la deuda de las familias cae en 25.000 millone...\n",
      "4    bestinver: no hay \"momento más inoportuno\" par...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Normalización: convertir a minúsculas\n",
    "train_df[\"text\"] = train_df[\"text\"].str.lower()\n",
    "test_df[\"text\"] = test_df[\"text\"].str.lower()\n",
    "\n",
    "print(\"\\nTexto preprocesado:\")\n",
    "print(train_df[\"text\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Descargar recursos necesarios\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar los datos de entrenamiento y prueba\n",
    "train_path = \"FinancES_train_kaggle.csv\"  # Ruta del archivo de entrenamiento\n",
    "test_path = \"FinancES_test_kaggle.csv\"    # Ruta del archivo de prueba\n",
    "\n",
    "# Cargar el modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Cargar modelo de spaCy para español (mejor que stemming para Word2Vec)\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Contar palabras más frecuentes en el dataset\n",
    "all_words = \" \".join(train_df[\"text\"]).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Eliminar palabras que aparecen en más del 80% de los documentos\n",
    "frequent_words = {word for word, freq in word_freq.items() if freq > 0.8 * len(train_df)}\n",
    "\n",
    "# Lista de stopwords personalizada\n",
    "custom_stopwords = set(stopwords.words('spanish'))\n",
    "\n",
    "# Agregar palabras irrelevantes para titulares financieros\n",
    "custom_stopwords.update({\"día\", \"años\", \"mes\", \"nuevo\", \"euros\"})\n",
    "\n",
    "# Añadir palabras frecuentes a la lista de stopwords\n",
    "custom_stopwords.update(frequent_words)\n",
    "\n",
    "# Función de preprocesamiento con Lematización y stopwords mejoradas\n",
    "def preprocess_text(text):\n",
    "    # Tokenización con spaCy\n",
    "    doc = nlp(text.lower())  # Convertir a minúsculas y procesar con spaCy\n",
    "\n",
    "    # Eliminar stopwords y obtener lemas\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in custom_stopwords and not token.is_punct]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_vector(text, model):\n",
    "    words = word_tokenize(text)\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    \n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)  # Promedio de los vectores de las palabras\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Vector de ceros si el texto no tiene palabras conocidas\n",
    "\n",
    "# Convertir todos los textos a vectores\n",
    "X_train = np.array([text_to_vector(text, word2vec_model) for text in train_df[\"text\"]])\n",
    "X_test = np.array([text_to_vector(text, word2vec_model) for text in test_df[\"text\"]])\n",
    "y_train = train_df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score por Fold: [0.38055917 0.37926724 0.38706388 0.39192533 0.39188714]\n",
      "F1-Score promedio: 0.38614055452637286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Aplicar validación cruzada con los hiperparámetros encontrados\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2, random_state=42)\n",
    "\n",
    "scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='f1_macro')\n",
    "\n",
    "print(\"F1-Score por Fold:\", scores)\n",
    "print(\"F1-Score promedio:\", scores.mean())\n",
    "\n",
    "# Entrenar el modelo con los datos completos\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones para el conjunto de test\n",
    "test_predictions = rf_model.predict(X_test)\n",
    "test_df[\"label\"] = test_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO CREO QUE FUNCIONE PERO EN CUALQUIER CASO, LO QUE CREO QUE ES LO ÚNICO QUE PODRÍA HACER FUNCIONAR A ESTO ES COGER UNOS EMBEDDINGS PREENTRENADOS [LINK A WORD EMBEDDINGS EN ESPAÑOL DE GITHUB](https://github.com/dccuchile/spanish-word-embeddings)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
